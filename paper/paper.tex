\documentclass[a4paper]{eccomas_paper-2024}

\usepackage{graphicx}
\usepackage{subfig}
\usepackage{url}
\usepackage{amsmath}
\usepackage{amsfonts}
\usepackage{amssymb}
\usepackage{bm}
\usepackage{upgreek}
\usepackage{physics}
\usepackage{cleveref}
\usepackage{algorithm, algorithmicx, algpseudocode}

\usepackage[%
backend=biber,
style=numeric, %alphabetic, numeric
giveninits=true,
natbib=true,
url=false,
doi=true,
eprint=false,
isbn=false,
defernumbers=true,
labelnumber,
hyperref=false,
maxbibnames=3,
sorting=none,%remove this to have things sorted, e.g. use style=alphabetic
]{biblatex}
\addbibresource{main.bib}
\addbibresource{references.bib}

\usepackage[commentmarkup=uwave]{changes}
\usepackage{xspace}

\usepackage{tikz}
\usepackage{standalone}
\usepackage{booktabs}
\usepackage{tabularx}
\usepackage{pgfplotstable}
\pgfplotsset{compat=1.18}
\usetikzlibrary{%
	calc,
	patterns,
	positioning,
	decorations.pathreplacing,%
	decorations.pathmorphing,%
	arrows.meta,%
}
\usepackage{bamcolors}

\definechangesauthor[color=blue, name={Philipp Diercks}]{pd}
\definechangesauthor[color=red, name={Joerg F. Unger}]{jfu}
\definechangesauthor[color=orange, name={Annika Robens-Radermacher}]{arr}

% %%% Custom commands
\newcommand{\ie}{i.\,e.\@\xspace}
\newcommand{\eg}{e.\,g.\@\xspace}
% suffixes
\newcommand{\m}{\bm\mu}
\newcommand{\gl}{\mathrm{gl}}
\newcommand{\p}{\mathrm{p}}
\newcommand{\out}{\mathrm{out}}
\newcommand{\inrm}{\mathrm{in}}
\newcommand{\fom}{\mathrm{fom}}
\newcommand{\rom}{\mathrm{rom}}
\newcommand{\train}{\mathrm{train}}
% operators
\newcommand{\vecm}{\mathrm{vec}}
\renewcommand{\top}{\mathrm{T}}

\urldef{\gradientenbetonurl}\url{https://gradientenbeton.eu/}
\graphicspath{{./img/}}

% \usepackage{stanli}

\title{AN EFFICIENT LOCALIZED MODEL ORDER REDUCTION FRAMEWORK FOR THE SHAPE OPTIMIZATION OF ADDITIVELY MANUFACTURED LATTICE STRUCTURES\break ECCOMAS CONGRESS 2024}

\author{Philipp Diercks$^{1}$, Karen Veroy$^{2}$, Annika Robens-Radermacher$^{1}$ and Jörg F. Unger$^{1}$}

% heading is supposed to contain only the authors (on all pages except the first page)
\heading{Philipp Diercks, Karen Veroy, Annika Robens-Radermacher and Jörg F. Unger}

\address{$^{1}$ Bundesanstalt für Materialforschung und -prüfung, Unter den Eichen 87, 12205 Berlin, \{philipp.diercks, annika.robens-radermacher, joerg.unger\}@bam.de, \url{www.bam.de}
\and
$^{2}$ Centre for Analysis, Scientific Computing and Applications (CASA), Department of Mathematics and Computer Science, TU Eindhoven, P.O. Box 513, 5600 MB Eindhoven, The Netherlands, k.p.veroy@tue.nl}

\keywords{Multiscale methods, Domain decomposition methods, Model order reduction, parameterized PDEs, Shape optimization}

% TODO abstract
\abstract{\comment[id=pd]{TODO: add abstract}.}

\begin{document}
\thispagestyle{empty}

\section{INTRODUCTION}%
\label{sec:introduction}

Additive manufacturing (AM), commonly known as 3D printing, is a manufacturing technique that allows for the production of a wide range of structures and complex geometries.
The objects are build successively by adding material layer by layer from three-dimensional models.
The technology offers numerous advantages over conventional manufacturing, including greater design flexibility, reduced material waste, and the possibility to produce complex structures with tailored material properties.
It has been used in a wide range of applications, including aerospace, biomechanical, automotive, and construction industries~\cite{Plessis2022Properties,Wu2016critical}.

A common engineering practice is to optimize the geometry of a structure by an iterative process, in which an objective function is minimized by systematically choosing parameter values $\bm\mu$ (design variables) and computing the value of the function.
In structural mechanics, a prominent example of an objective function is mass or compliance which is a function of the parameter-dependent displacement field $\bm{u}(\bm\mu)$.
In each iteration of the optimization process, the geometry is manually changed in the CAD model and the high fidelity finite element (FE) model, also called full order model (FOM), is simply re-evaluated.
While this approach is not only an ineffective use of resources, it is also infeasible when solving the FE model is a computationally demanding task, \eg{} in multiscale or large-scale industrial applications.
Due to the prohibitive cost of even a single FOM solution, the iterative design process cannot be performed using direct numerical simulations.
Therefore, we propose a framework based on localized, also called component-based (CB), parametric model order reduction (pMOR).
The main idea is to precompute, in a localized manner, empirical basis functions which approximate the solution for some part of the domain without the need to solve the global FOM even once.
The global approximation is obtained by a suitable coupling of the local reduced spaces spanned by the aforementioned basis functions, in which one naturally relies on domain decomposition (DD) strategies.
A review of concepts in localized model order reduction is presented in~\cite{BuhrReview}.
In particular, regarding lattice structures, this approach allows to take advantage of the repetitiveness of the lattice, such that a computation of the local basis is required only for few components, \ie{} unit cells.

The computation of the local basis is an essential task in localized pMOR and is often done using the concept of oversampling~\cite{Hou1997Multiscale}.
In this approach, the target subdomain $\varOmega_{\mathrm{in}}$, \ie{} that part of the domain for which one would like to construct basis functions, is extended and boundary conditions are prescribed on the boundary of the larger so-called oversampling domain $\varOmega$ to explore possible solutions.
In the literature, this oversampling problem is also expressed in terms of a \textit{transfer operator} $\bm{T}$ that maps the values on the boundary $\partial\varOmega$ to the unknown solution restricted to the target subdomain $\bm{u}(\bm{\mu})\vert_{\varOmega_{\mathrm{in}}}$.
The construction of (optimal) local approximation spaces then comprises the calculation of the left singular vectors of this transfer operator~\cite{Babuska2011Optimal,Smetana2016Optimal}.
The direct calculation via eigenvalue problems is, however, computationally expensive and the range of the transfer operator, and thus the optimal local approximation spaces can be efficiently approximated by random sampling~\cite{Buhr2018Randomized}.
Here, the authors treat non-parametrized partial differential equations (PDEs) and to our knowledge the extension to the parametric setting for linear problems has not been done yet.
In~\cite{Smetana2016Optimal}, the authors propose a spectral greedy algorithm to construct parameter-independent local approximation spaces and Taddei and Patera~\cite{Taddei2018Localization} propose a combination of transfer eigenproblems and proper orthogonal decomposition (POD).
For parameterized nonlinear elliptic PDEs Smetana and Taddei~\cite{Smetana2023Localized} present a randomized local training procedure with global enrichment.

The contributions of the present work are given as follows.
First, as references~\cite{Smetana2016Optimal,Taddei2018Localization} do not make use of range approximation via random sampling, a suitable training strategy to construct local approximation spaces for parameterized linear problems via random sampling is discussed.
Herein, the approach given in~\cite{Taddei2018Localization}, identified as a \textit{distributed approximate POD} (see also~\cite{Himpe2018Hierarchical}), is adopted to range approximation via random sampling.
Second, a framework for the shape optimization of lattice structures is proposed.
It combines the aforementioned algorithm to construct local approximation spaces with an auxiliary problem, as in~\cite{Guo2022Learning}, to facilitate geometrical parametrizations of the unit cell and the matrix version~\cite{Negri2015Efficient} of the empirical interpolation method (EIM)~\cite{Barrault2004‘empirical,Chaturantabut2010Nonlinear} to ensure online efficiency of the final reduced order model (ROM).
Furthermore, the global approximation space is constructed from the local spaces using the partition of unity method or generalized finite element method (GFEM)~\cite{BABUSKA1997,Babuska2004Generalized}.

The rest of the article is organized as follows.
In~\cref{sec:method}, the building blocks of the shape optimization framework are described.
In particular, the range approximation of a parametric transfer operator is discussed.
\Cref{sec:numerical experiments} comprises the numerical experiments.
Based on the example of a graded concrete slab, the quality of the local spaces generated by the proposed method is analyzed, the resulting ROM is validated, and results for the solution of a shape optimization problem are presented.
Finally, conclusions are given in~\cref{sec:conclusions}.

\added[id=pd]{TODO: add note on notation where appropriate.}\\
\added[id=pd]{TODO: shorten introduction.}

\section{METHOD}%
\label{sec:method}
The method proposed in this article is a localized pMOR framework for the shape optimization of lattice structures.
First, the auxiliary problem to model geometrical parameterizations is introduced in~\cref{sub:Auxiliary Problem}.
Second, the construction of local approximation spaces is described in~\cref{sub:Construction of local approximation spaces}.
Herein, the parametric oversampling problem and training strategy to approximate the range of the corresponding parametric transfer operator are discussed.
Third, it is outlined how a global approximation is obtained from local approximation spaces via the GFEM.
Finally, the hyper-reduction (in the form of empirical interpolation) to ensure an online-efficient ROM is detailed in~\cref{sub:Online efficiency}.

\subsection{Auxiliary Problem} % (fold)
\label{sub:Auxiliary Problem}
The approach adopted in this work to facilitate geometrical parameterizations belongs to the class of surface-based deformations~\cite{Botsch2010Polygon} and is based on transformations $\Phi_{\bm\mu}$ that map each material point $\bm{x}_{\mathrm{p}}$ of a parameter-independent reference or parent domain $\varOmega^{\mathrm{p}}$ to a point $\bm{x}_{\bm\mu}$ in the parameter-dependent current or physical domain $\varOmega^{\bm\mu}$.
In the context of shape optimization of lattice structures, our objective is to determine the mapping $\Phi_{\bm\mu}$ for a single unit cell, see~\cref{fig:transformationmap}, and use it to describe the change in geometry of each unit cell throughout the structure.
% The auxiliary problem is formulated here for a single unit cell, and for ease of notation the subscript $i$ as employed in the remainder of the article is dropped.
An auxiliary problem based on the equations of linear elasticity is solved to obtain such domain transformations, following the approach outlined in~\cite{Guo2022Learning}, and briefly repeated here for completeness.

The transformation map $\Phi_{\bm\mu}$ from parent to physical domain $\Phi_{\bm\mu}: \varOmega^{\mathrm{p}}\mapsto\varOmega^{\bm\mu}$ is given by $\bm{x}_{\bm\mu}=\Phi_{\bm\mu}(\bm{x}_{\mathrm{p}}) = \bm{x}_{\mathrm{p}} + \bm{d}(\bm{x}_{\mathrm{p}}; \bm\mu)$, 
with $\bm{d}(\bm{x}_{\mathrm{p}}; \bm{\mu})$ being the transformation displacement field.
The transformation displacement is determined by solving the following linear elastostatic auxiliary problem.
\begin{align}
    \label{eq:aux_1}\div{\left(\hat{\mathbb{C}}\vdot\!\vdot\frac{1}{2}\left(
            \bm{d}\otimes\grad + \grad\otimes\bm{d}
\right)\right)}
            = \bm{0}\,,\quad&\mathrm{in}\;\varOmega^{\mathrm{p}}\,,\\
    \label{eq:aux_2}\bm{d} = \bm{0}\,,\quad&\mathrm{on}\;\partial\varOmega^{\mathrm{p}}\,,\\
    \label{eq:aux_3}\bm{d} = \bm{x}_{\mu} - \bm{x}_{\mathrm{p}}\,,\quad&\mathrm{on}\;\partial\varOmega^{\mathrm{p}}_{\mathrm{int}}\,.
\end{align}
The stiffness tetrad $\hat{\mathbb{C}}$ of the auxiliary problem is defined as
\begin{equation}
    \hat{\mathbb{C}} = \hat{\lambda} \bm{I}\otimes\bm{I} + 2\hat{\mu}\mathbb{I}\,,\quad\mathrm{with}\quad \hat{\lambda}=\frac{\nu}{(1+\nu)(1-2\nu)}\quad\mathrm{and}\quad\hat{\mu}=\frac{1}{2(1+\nu)}\,.
    \label{eq:aux_tetrad}
\end{equation}
With $\bm{x}_{\bm\mu}$ known for all points on the parent interface $\partial\varOmega^{\mathrm{p}}_{\mathrm{int}}$, the desired transformation (\eg{} enlarging/shrinking of the voids radius) is enforced by prescribing~\cref{eq:aux_2,eq:aux_3}.

Given the transformation displacement $\bm{d}(\bm{x}_{\mathrm{p}};\bm\mu)$, the variational formulation is formulated over the parameter-independent parent domain $\varOmega^{\mathrm{p}}$ instead of the parameter-dependent physical domain $\varOmega^{\bm\mu}$.
This introduces the parameter dependence in the variational formulation as shown in the following subsections, but has the advantage that numerical integration can be carried out over the fixed parent domain and thus no re-meshing is required.
However, for each new parameter value $\bm\mu$ for which the model is to be evaluated, we first need to solve the auxiliary problem.
Nevertheless, this does not pose a problem, since the solution of the auxiliary problem is well amenable to acceleration via established MOR techniques and we refer to~\cite{Guo2022Learning} for further details.

\begin{figure}
    \centering
    \include{./img/transformationmap.tex}
    \caption{Transformation map $\Phi_{\bm\mu}$ from parent to physical domain on the example of the unit square domain with a circular void placed in the center. The parameter $\bm\mu$ controls the radius of the void.}\label{fig:transformationmap}
\end{figure}

% subsection Auxiliary Problem (end)

\subsection{Construction of local approximation spaces} % (fold)
\label{sub:Construction of local approximation spaces}
In this paper, local approximation spaces are constructed by solving an oversampling problem many times for different parameter values $\bm\mu$ and different (random) boundary conditions.
It is therefore useful to cast this oversampling problem in the form of a parameter-dependent transfer operator $\bm{T}_{\bm\mu}$ that
maps the boundary function $\bm{g}$ to the solution $\bm{u}(\bm\mu)$ in the target subdomain $\varOmega^{\m}_{\mathrm{in}}$.
The approximation of the range of this transfer operator is then the local approximation space, see~\cite{Buhr2018Randomized}.

First, the global domain $\varOmega_{\mathrm{gl}}^{\bm\mu}$ and a non-overlapping domain decomposition
\begin{equation}
	\varOmega_{\mathrm{gl}}^{\bm\mu}=\cup_{i=1}^{N_{\mathrm{cells}}} \varOmega_i^{\bm\mu}
\end{equation}
is introduced.
In the context of lattice structures, each subdomain $\varOmega_i^{\bm\mu}$ corresponds to a unit cell.
Next, a coarse grid partition of the global domain and a fine grid partition of the unit cell is introduced as shown in~\cref{fig:oversampling_domain}.
\Cref{fig:oversampling_domain} also shows one exemplary oversampling domain $\varOmega^{\bm\mu}$.
The oversampling problem (given for linear elastostatics) then comprises the solution of the following boundary value problem.
\begin{align}
	\begin{split}
	\label{eq:osp_p}
    - \div{\bm{\sigma}} (\bm{u}(\bm\mu)) &= \bm{0} \quad  \mathrm{in}\;{\varOmega^{\bm\mu}}\subset\varOmega^{\bm\mu}_{\mathrm{gl}}\,,\\
    \bm{\sigma}(\bm{u}(\bm\mu)) \vdot \bm{n} &= \bm{0} \quad \mathrm{on}\; \varGamma^{\m}_{\mathrm{N}}:= \partial\varOmega^{\m}\cap\varSigma^{\m}_{\mathrm{N}}\,,\\
    \bm{u}(\bm\mu) &= \bm{0} \quad  \mathrm{on}\;\varGamma^{\m}_{\mathrm{D}}:=\partial\varOmega^{\m}\cap\varSigma^{\m}_{\mathrm{D}}\,,\\
    \bm{u}(\bm\mu) &= \bm{g}\quad\mathrm{on}\;\varGamma^{\m}_{\mathrm{out}}:= \partial\varOmega^{\m} \setminus\partial\varOmega^{\m}_{\mathrm{gl}}\,.
	\end{split}
\end{align}
Here, $\bm\sigma$ is the \textsc{Cauchy} stress, $\bm{n}$ the normal vector and $\bm{g}$ \textsc{Dirichlet} boundary data to be prescribed on the boundary $\varGamma^{\m}_{\out}$.
The boundaries $\varGamma^{\m}_{\mathrm{N}}$ and $\varGamma^{\m}_{\mathrm{D}}$ denote the part of the boundary of the oversampling domain that coincides with the global \textsc{Neumann} boundary $\varSigma^{\m}_{\mathrm{N}}$ or \textsc{Dirichlet} boundary $\varSigma^{\m}_{\mathrm{D}}$, respectively.
Note that the topology is dependent on the target subdomain $\varOmega^{\m}_{\inrm}$ and the size of the oversampled region.
Considering linear elastic isotropic materials
\begin{equation}
    \bm\sigma(\bm{u}(\m)) = \mathbb{C}\vdot\!\vdot\bm\varepsilon(\bm{u}(\m))\,,
    \label{eq:hooke}
\end{equation}
with the linear strain tensor as
\begin{equation}
    \label{eq:eps}
    \bm\varepsilon(\bm{w}):= \frac{1}{2}\left(\bm{w}\otimes\grad + \grad\otimes\bm{w}\right)\,,
\end{equation}
and the stiffness tetrad given in component form as
\begin{equation}
    C_{ijkl} = \lambda \delta_{ij}\delta_{kl} + \mu \left(\delta_{ik}\delta_{jl}+\delta_{il}\delta_{jk}\right)\,,
    \label{eq:stiffness_tetrad}
\end{equation}
the weak form reads
\begin{equation}
    \int_{\varOmega^{\m}} \pdv{\updelta\bm{u}}{\bm{x}^{\m}} \vdot\!\vdot \mathbb{C} \vdot\!\vdot
    \pdv{\bm{u}(\m)}{\bm{x}^{\m}} \dd{\bm{x}^{\m}} = \bm{0}\,.
    % -\int_{\varOmega^{\m}} \pdv{\updelta\bm{u}}{\bm{x}^{\m}} \vdot\!\vdot \mathbb{C} \vdot\!\vdot
    % \pdv{\hat{\bm{g}}}{\bm{x}^{\m}} \dd{\bm{x}^{\m}}\,.
    \label{eq:weak_osp}
\end{equation}
Herein, $\updelta\bm{u}$ denotes the test function.
% Herein, $\updelta\bm{u}$ denotes the test function and $\hat{\bm{g}}$ denotes a suitable lifting function for the inhomogeneous \textsc{Dirichlet} boundary condition and the solution is sought as $\bm{u}(\m)=\bm{u}_0(\m)+\hat{\bm{g}}$.
The weak form is implicitly dependent on the parameter $\m$ due to the integration carried out over the physical domain $\varOmega^{\m}$.
By introducing the deformation gradient of the geometrical transformation\footnote{We note here that the auxiliary problem described in~\cref{sub:Auxiliary Problem} needs to be extended to the oversampling domain, which consists of a union of unit cells. This is straightforward in the current setup, but has the limitation that \cref{eq:aux_2} needs to be satisfied for each unit cell, \ie{} the interfaces between them.} as introduced in~\cref{sub:Auxiliary Problem}
\begin{equation}
    \bm{F}_{\m}:= \dv{\bm{x}^{\m}}{\bm{x}^{\p}}\quad\mathrm{and}\quad
    \dd{\bm{x}^{\m}}=\det(\bm{F}_{\m})\dd{\bm{x}^{\p}}\,,
    \label{eq:F_mu}
\end{equation}
the integration can be carried out over the fixed parent domain
\begin{equation}
    \int_{\varOmega^{\p}} \left(\pdv{\updelta\bm{u}}{\bm{x}^{\p}}\vdot\bm{F}^{-1}_{\m}\right)\vdot\!\vdot \mathbb{C} \vdot\!\vdot
    \left(\pdv{\bm{u}(\m)}{\bm{x}^{\p}}\vdot\bm{F}^{-1}_{\m}\right)\det(\bm{F}_{\m})\dd{\bm{x}^{\p}} = \bm{0}\,.
    \label{eq:weak_osp_parent}
\end{equation}
The solution of the oversampling problem~\cref{eq:osp_p} is then given as the solution of~\cref{eq:weak_osp_parent} and subsequent restriction of the solution to the target subdomain, denoted as $\bm{u}(\m)\big\vert_{\varOmega^{\p}_{\inrm}}$.
The transfer operator $\bm{T}_{\m}: \mathcal{S}\to\mathcal{R}$ maps, for a given parameter value $\m$, the boundary data $\bm{g}$ to the solution on the target subdomain $\bm{u}(\m)\big\vert_{\varOmega^{\p}_{\inrm}} = \bm{T}_{\m}(\bm{g}).$
Here, $\mathcal{S}$ and $\mathcal{R}$ are appropriate source and range spaces, respectively.
Throughout the paper, we assume a suitable discretization and numerical solution of~\cref{eq:weak_osp_parent} using the FE method.
For details concerning the discretization of the transfer operator (for a fixed parameter value), we refer to~\cite{Buhr2018Randomized}.

Finally, we note that the images of $\bm{T}_{\m}$ are computed, such that they do not contain any translations or rotations (rigid body modes are removed via orthogonal projection), \ie{} they comprise purely \textit{deformational modes}.
Moreover, (global) \textsc{Neumann} or \textsc{Dirichlet} boundary conditions prescribed on $\varSigma^{\m}_{\mathrm{N}}$ or $\varSigma^{\m}_{\mathrm{D}}$, respectively, have not been considered yet.
Therefore, an additional \textsc{Neumann} problem\footnote{The case of inhomogeneous \textsc{Dirichlet} boundary conditions can be treated in the same way.} has to be solved to enrich the local spaces.
\begin{align}
	\begin{split}
	\label{eq:neumann_problem}
    - \div{\bm{\sigma}} (\bm{u}(\bm\mu)) &= \bm{0} \quad  \mathrm{in}\;{\varOmega^{\bm\mu}}\subset\varOmega^{\bm\mu}_{\mathrm{gl}}\,,\\
    \bm{\sigma}(\bm{u}(\bm\mu)) \vdot \bm{n} &= \hat{\bm{t}} \quad \mathrm{on}\; \varGamma^{\m}_{\mathrm{N}}:= \partial\varOmega^{\m}\cap\varSigma^{\m}_{\mathrm{N}}\,,\\
    \bm{u}(\bm\mu) &= \bm{0} \quad  \mathrm{on}\;\varGamma^{\m}_{\mathrm{D}}:=\partial\varOmega^{\m}\cap\varSigma^{\m}_{\mathrm{D}}\,,\\
    \bm{u}(\bm\mu) &= \bm{0}\quad\mathrm{on}\;\varGamma^{\m}_{\mathrm{out}}:= \partial\varOmega^{\m} \setminus\partial\varOmega^{\m}_{\mathrm{gl}}\,.
	\end{split}
\end{align}
\Cref{eq:neumann_problem} is solved on the parent domain employing the pull back as above.
Also, for construction of a sufficiently rich local basis it has to be solved for many parameter values $\m$, but a sampling of the boundary values on $\varGamma^{\m}_{\out}$ is not required.
% - setting, global domain = union of non overlapping subdomains = unit cells
% - introduction of coarse grid where each cell corresponds to unit cell subdomain
% - goal of constructing local spaces for only parts of the domain
% - definition of oversampling problem and transfer operator
% these are details of the specific problem we solve later
% - the oversampling problem should be formulated for union of parent unit cells
% - weak formulation is not required here? Should be first introduced in section 2.3?
% - comment on number of archetypes/configurations

\begin{figure}
    \centering
    \include{./img/oversampling_domain.tex}
    \caption{Exemplary coarse grid discretization of the global domain $\varOmega^{\m}_{\gl}$, with target subdomain $\varOmega^{\m}_i$ within oversampling domain $\varOmega^{\m}$ in grey (a) and fine grid discretization of the unit cell (b).}\label{fig:oversampling_domain}
\end{figure}

% TODO adjust abovecaptionskip if necessary
% it seems the default is 6pt (see class file)
% \setlength{\abovecaptionskip}{15pt plus 3pt minus 2pt}

% subsection Construction of local approximation spaces (end)

\subsubsection{Randomized range finder and proper orthogonal decomposition} % (fold)
\label{sec:Randomized range finder and POD}

Assuming a proper FE discretization of $\bm{T}_{\m}$, the algorithm to approximate the range of $\bm{T}_{\m}$ for any $\m$ is discussed next.
Herein, a strategy for the exploration of the parameter space and sampling of the random boundary conditions in the oversampling are the key challenges.
In the present work, the strategy by Taddei \& Patera~\cite{Taddei2018Localization} is adopted in which based on the connection between the POD of images of the transfer operator (for certain boundary conditions) and the singular values of the transfer operator they devise a training strategy which is recognized as a distributed approximate POD (see \cite{Himpe2018Hierarchical}).
For each $\m_j$ in a predefined training set, they compute the singular values of $\bm{T}_{\m_j}$ by solution of an eigenvalue problem and, subsequently, compute the POD over the set of all eigenvectors.
As the authors state, the resolution of the eigenvalue problems may be prohibitive in some cases, and therefore we employ range approximation by random sampling.

The procedure for the computation of parameter-independent deformational modes is summarized in~\cref{algo:rrfpod}.
The target tolerance $\varepsilon^{\ast}$ is used to control the quality of the approximation space (by bounding the mean $\ell^2$-error), and to compute the local tolerances $\varepsilon_{\alpha}$ that steer the range approximation of each transfer operator and the tolerance $\varepsilon_{\rho}$ for the final POD.
First, an empty snapshot set $\bm{S}$ and a training set $\bm{S}_{\mathrm{train}}$ are initialized.
The training set $\bm{S}_{\mathrm{train}}$ has to be sufficiently rich, such that it is a good representation of the parameter space, and the reader is referred to~\cite{Haasdonk2017Chapter}.
Next, for each parameter value $\m_j\in\bm{S}_{\mathrm{train}}$, the range of $\bm{T}_{\m_j}$ which is now fixed with respect to the parameter value is approximated using Algorithm 1 \textsc{AdaptiveRandomizedRangeApproximation} from~\cite{Buhr2018Randomized} (line 6).
If $\partial\varOmega^{\p}\cap\varSigma^{\p}_{\mathrm{N}}\ne\emptyset$, the additional \textsc{Neumann} problem~\cref{eq:neumann_problem} is solved and the solution appended to the current range $\bm{R}$ (lines 7-9).
The set of snapshots is then extended by the current range $\bm{R}$ (line 11).
Note that the parameter value $\m$ and boundary conditions $\bm{g}$ are not varied at the same time.
Finally, the POD is computed over the snapshot set $\bm{S}$ which yields the parameter-independent space $X^n$.
The dimension of the local space $X^n$, \ie{} the number of local basis functions is denoted by $n$.

\begin{algorithm}
    \caption{Randomized range finder (RRF) combined with POD.}%
    \label{algo:rrfpod}
    \begin{algorithmic}[1]
        \Function{HapodRangeApproximation}{$\bm{T}$, $\varepsilon^{\ast}$, $n_t$, $\varepsilon_{\mathrm{algofail}}$, $N_{\mathrm{train}}$}
        \Statex{\textbf{Input:} Operator $\bm{T}_{\bm\mu}$, target tolerance $\varepsilon^{\ast}$, number of testvectors $n_t$, maximum failure probability $\varepsilon_{\mathrm{algofail}}$, number of parameter samples $N_{\mathrm{train}}$}
    \Statex{\textbf{Output:} space $X^n$}

    \State{Compute $\varepsilon_{\rho}$ and $\varepsilon_{\alpha}$ from $\varepsilon^{\ast}$ according to Theorem 10 of~\cite{Himpe2018Hierarchical}}
    \State{$\bm{S}$ $\gets\;\emptyset$}\Comment{initialize snapshot set}
    \State{$\bm{S}_{\mathrm{train}}\gets\;\{\bm\mu_1,\ldots,\bm\mu_{N_\mathrm{train}}\}$}\Comment{initialize training set}
    \For{$\bm\mu_j$ in $\bm{S}_{\mathrm{train}}$}
    \State{$\bm{R}\gets$ \textsc{AdaptiveRandomizedRangeApproximation}($\bm{T}_{\bm\mu_j}$, $\varepsilon_{\alpha}$, $n_t$, $\varepsilon_{\mathrm{algofail}}$)}
    % \State{$\bm{u}_{\mathrm{Neumann}}(\bm\mu_j)\gets \bm{T}_{\bm\mu_j}(\bm{0})$}\Comment{solve additional Neumann problem if $\varGamma_{\mathrm{N}}\ne\emptyset$}
    % \State{$\bm{R}\gets \bm{R}\cup\left(\bm{u}_{\mathrm{Neumann}}(\bm\mu_j)\right)$}
    \If{$\partial\varOmega^{\p}\cap\varSigma^{\p}_{\mathrm{N}}\ne\emptyset$}
        \State{$\bm{u}_{\textsc{Neumann}}\gets$ Solve \cref{eq:neumann_problem} for $\m_j$ }
        \State{$\bm{R} \gets \bm{R}\cup\bm{u}_{\mathrm{Neumann}}$}
    \EndIf
    \State{$\bm{S}\gets \bm{S}\cup\bm{R}$}
    \EndFor%
    \State{$\bm{B}\gets\textsc{POD}(\bm{S}, \varepsilon_{\rho})$}
    \State{\textbf{return} {$X^n=\mathrm{span}\left(\bm{B}\right)$}}
    \EndFunction%
    \end{algorithmic} 
\end{algorithm}

% subsubsection Randomized range finder and POD (end)

\subsection{Construction of a global approximation} % (fold)
\label{sub:Construction of a global approximation}
Given local approximation spaces $X^n_i$ for each target subdomain $\varOmega_i^{\p}$, the construction of a global approximation via the GFEM is discussed.
The difficulty is that the basis functions of the local spaces $X^n_i$ and $X^n_j$ of two neighboring subdomains $\varOmega_i^{\p}$ and $\varOmega_j^{\p}$ are not conforming on the shared interface $\varGamma^{\p}_{ij}=\partial\varOmega_i^{\p}\cap\partial\varOmega_j^{\p}$.
However, given a suitably\footnote{According to Definition 1 of~\cite{BABUSKA1997}.} defined partition of unity $\{{\varphi}_i\}$, the local basis functions can be included in the global FE space by multiplication with the standard FE shape functions ${\varphi}_i$, such that a conforming approximation is obtained.
The global GFEM space is defined as
\begin{equation}
	\label{eq:Xgfem}
    X_{\mathrm{GFEM}}:= \sum_{i} \varphi_iX^n_i = \left\lbrace\sum_i\varphi_i\bm\xi_i \;\big|\; \bm\xi_i\in X^n_i	\right\rbrace\,.
\end{equation}
Furthermore, the GFEM function denoted as $\bm{\psi}(\bm{x}) = \varphi(\bm{x})\bm{\xi}(\bm{x}), \bm{x}\in\omega_{\alpha}$ for a patch $\omega_{\alpha}$ is shown in~\cref{fig:gfem} to illustrate the procedure of constructing the GFEM functions.
\begin{figure}[h]
    \centering
    \subfloat[Linear hat function $\varphi(\bm{x})$]{%
          \includegraphics[height=5cm]{phi.pdf}%
          \label{fig:gfem_left}%
       }\hfill 
       \subfloat[Enrichment function $\bm{\xi}(\bm{x})$]{%
          \includegraphics[height=5cm]{enrichment.pdf}%
          \label{fig:gfem_middle}%
       }\hfill
       \subfloat[GFEM function $\bm\psi(\bm{x})$]{%
          \includegraphics[height=5cm]{gfem_function.pdf}%
          \label{fig:gfem_right}%
       }
       \caption{Construction of GFEM functions.}
       \label{fig:gfem}
\end{figure} 

% subsection Construction of a global approximation (end)

\subsection{Global solution procedure} % (fold)
\label{sub:Online efficiency}
With the global GFEM space, each coarse grid cell (\ie{} unit cell of the lattice) can be viewed as a high order FE.
For instance, assuming a coarse grid partition as shown in~\cref{fig:oversampling_domain}, the coarse grid cell is a quadrilateral cell with special ansatz functions $\bm{\psi}_i$.
The components of the FE matrix of the $i-$th coarse grid cell are given by
\begin{align}
    \begin{split}
        a^i_{kl} &= \int_{\varOmega^{\p}_i} \left(\pdv{\bm{\psi}_k}{\bm{x}^{\p}}\vdot\bm{F}^{-1}_{\m}\right)\vdot\!\vdot \mathbb{C} \vdot\!\vdot
    \left(\pdv{\bm{\psi}_l}{\bm{x}^{\p}}\vdot\bm{F}^{-1}_{\m}\right)\det(\bm{F}_{\m})\dd{\bm{x}^{\p}}\,,\\
                 &= ({V}^\top)_{km} {K}_{mn}(\m){V}_{nl}\,.
    \end{split}
    \label{eq:element_matrix}
\end{align}
Here, $\bm{V}$ is the matrix that holds the FE vectors of the GFEM functions $\bm\psi_i$ as column vectors and $\bm{K}(\m)$ is the stiffness matrix of the subdomain $\varOmega^{\p}_i$ (\ie{} unit cell).
Since $\bm{K}$ is dependent on the parameter $\m$, integration over the full fine scale mesh of the unit cell is required whenever the model is evaluated for a new parameter value which will drastically reduce the computational efficiency of our method.

To overcome this problem, the stiffness matrix $\bm{K}(\m)$ is approximated by Empirical Interpolation~(see \cite{Barrault2004‘empirical,Chaturantabut2010Nonlinear} and in particular \cite{Negri2015Efficient} for the matrix version termed MDEIM employed here), such that
\begin{equation}
    \bm{K}(\m) \approx \bm{K}_Q(\m) =\sum_{q=1}^{Q} \theta_q(\m) \bm{K}_q\,.
    \label{eq:K_ei}
\end{equation}
Herein, $\bm{K}_q$ are parameter-independent matrices that can be precomputed\footnote{Due to the Galerkin projection onto $\bm{V}$ (\cref{eq:element_matrix}) the matrices to be precomputed and stored are also sufficiently small.}.
The $\bm\theta(\m)\in\mathbb{R}^Q$ are called interpolation coefficients and can be determined via the interpolation equation
\begin{equation}
    \bm{\Phi}_{\mathcal{I}}\bm\theta(\m) = \bm{k}_{\mathcal{I}}(\m)\,.
    \label{eq:interp}
\end{equation}
Considering the matrix version of DEIM, the interpolation is constructed for matrices that are vectorized by stacking their columns on top of each other which is denoted by $\bm{k}=\vecm(\bm{K})$.
The suffix $(\cdot)_{\mathcal{I}}$ indicates the restricted evaluation, reduced integration respectively.
The basis $\bm{\Phi}=[\vecm(\bm{K}_1), \ldots, \vecm(\bm{K}_Q)]$ and the interpolation indices $\mathcal{I}$ are determined by applying the DEIM algorithm as proposed in~\cite{Chaturantabut2010Nonlinear} to a set of snapshots $\{\vecm(\bm{K}(\m_1)), \ldots, \vecm(\bm{K}(\m_m))\}$, $m>0$.
By reversing the $\vecm(\cdot)$ operation, the approximation $\bm{K}_Q(\m)$ can be formed using~\cref{eq:K_ei} once the interpolation coefficients are determined by solution of \cref{eq:interp}.
For more details on the overall procedure the reader is referred to~\cite{Negri2015Efficient}.

Finally, with a fast method to compute $\bm{K}_Q(\m)$, the calculation of the FE matrices $a^i_{kl}$ of each coarse grid cell are independent of the underlying fine grid discretization of the unit cell.
The assembly of the global system matrix follows the usual assembly routine for FE methods.

% subsection Online efficiency (end)

\section{NUMERICAL EXPERIMENTS} % (fold)
\label{sec:numerical experiments}
% The proposed methodology to construct the ROM is evaluated based on the example of a graded concrete slab. In~\cref{sub:Projection error study}, the approximation quality of the local spaces is accessed by studying the projection error. The ROM is validated against the FOM (\cref{sub:Reduced order model validation}) and the solution of a shape optimization problem is presented in~\cref{sub:Shape optimization}.
% \comment[id=pd]{TODO: remove these sentences in case the article is too long.}

% section numerical experiments (end)

\subsection{Graded concrete slab} % (fold)
\label{sub:Graded concrete slab}
The numerical example investigated here is motivated by \textit{graded concrete} in which voids are created by inserting hollow bodies into the concrete formwork with the goal of mass reduction, see~\gradientenbetonurl.
The problem is simplified and we consider a two dimensional beam under plane stress conditions as shown in~\cref{fig:beam_sketch}.
The coarse grid partition of half of the beam body $\varOmega^{\p}_{\gl}=[0, 10a]\times[0, a]$ is given by $10$ quadrilateral cells of size $a$, where $a$ is the unit length of the unit cell.
Each unit cell, \ie{} subdomain $\varOmega^{\p}_i$, is taken as a square of size $a$ with a circular void with radius $R$ and is partitioned in 384 isoparametric quadrilateral FEs of polynomial degree two, see~\cref{fig:oversampling_domain}\,(b).
With regard to the geometrical parametrization, we consider the variation of the radius $R$ in each subdomain.
For the global problem this results in a parameter space $\mathcal{P}_{\gl}=[R_{-}, R_{+}]^{10}$, such that a parameter value $\m\in\mathcal{P}_{\gl}$ has parameter components $\mu_i\in[R_{-},R_{+}], i=1, \ldots, 10$, with ranges chosen as $R_{-}=0.1a, R_{+}=0.3a$.
For the parent domain we set $\bar{\mu}_i=0.2a, i=1, \ldots, 10$ as the reference value.
The point load is distributed as a constant traction over the length of one unit cell (on the far left).

\paragraph{Full order model}
An auxiliary problem is defined on the global domain $\varOmega^{\p}_{\gl}$ to account for the variation in the geometry.
The full order model is given by a standard FE model using the fine grid discretization of $\varOmega^{\p}_{\gl}$ as described above.

\paragraph{Reduced order model}
The ROM is constructed using the procedure for range approximation described in~\cref{sub:Construction of local approximation spaces}.
Using the coarse grid as above, we choose to solve $k=1, \ldots, 11$ oversampling problems, such that for each of the target subdomains $\varOmega^{\p, k}_{\inrm}$ and $\varOmega^{\p, k+1}_{\inrm}$ an overlap of size $a\times a$ is created.
The pointwise overlap condition is required for the construction of the GFEM functions.
The size of the target subdomain $\varOmega^{\p, k}_{\inrm}$ is $2a \times a$ for $k=2, \ldots, 10$ and $a \times a$ for $k = 1, 11$.
For each problem the oversampling layer has size $a \times a$, \ie{} the target subdomain is extended by a unit cell on each side unless the boundary of the target subdomain intersects with the boundary of the global domain ($\partial\varOmega^{\p,k}_{\inrm}\cap\partial\varOmega^{\p}_{\gl}\ne\emptyset$).

The input parameters to~\cref{algo:rrfpod} are $\varepsilon^{\ast}=0.001\,, n_t=\dim(\mathcal{S})$ and $\varepsilon_{\mathrm{algofail}}=1\cdot\,10^{-14}$ for $k=1, \ldots, 11$, where $\dim(\mathcal{S})$ denotes the dimension of the source space of the transfer operator and corresponds to the number of degrees of freedom on the boundary $\varGamma^{\p}_{\out}$ in the FE model.
The number of training samples is chosen as $N_{\train}=50$ ($k=1, 11$), $N_{\train}=100$ ($k=2, 10$) and $N_{\train}=200$ elsewhere, as the local parameter spaces have different dimensions.
The singular values of the POD at the end of~\cref{algo:rrfpod} for each oversampling problem show a rapid decay~(\cref{fig:singular_values}).
As expected, a less rapid decay is observed for the larger oversampling domains.
Furthermore, for $k=1, 2, 3$ in comparison to the oversampling problems of the same size on the right ($k=9, 10, 11$), a difference in the total number of snapshots generated is observed which is due to the additional \textsc{Neumann} problems.

% There is not enough space for this figure
% \begin{figure}
%     \begin{center}
%         \includegraphics[keepaspectratio,height=4cm]{gradientenbeton_formwork.jpg}
%     \end{center}
%     \caption{Formwork for a graded concrete slab. Weight savings are achieved by placing hollow spheres along a structured grid inside the formwork. Source:\gradientenbetonurl.}\label{fig:gradientenbeton}
% \end{figure}

\begin{figure}[h]
    \centering
    \subfloat[Mechanical model of the beam]{%
          \includegraphics[keepaspectratio]{traeger.pdf}%
          \label{fig:beam_sketch_left}%
       }\hfill 
       \subfloat[Simulation model of half of the beam]{%
          \includegraphics[keepaspectratio, scale=0.8]{halfbeam.pdf}%
          \label{fig:beam_sketch_right}%
       }
       \caption{Mechanical model of the beam and representation of the simulation model with loads and kinematical constraints.}
       \label{fig:beam_sketch}
\end{figure} 

\begin{figure}
    \begin{center}
        \includegraphics[width=0.6\textwidth]{singular_values.pdf}
    \end{center}
    \caption{Decay of singular values for each of the $11$ oversampling problems. The total number of basis functions and the total number of snapshots are given in the legend.}\label{fig:singular_values}
\end{figure}

% subsection Graded concrete slab (end)

\subsection{Reduced order model validation} % (fold)
\label{sub:Reduced order model validation}

For the validation of the ROM, the relative error with respect to the FOM is computed over a parameter set of size $200$.
The error in the displacements is measured in the energy norm (over the domain $\varOmega^{\p}_{\gl}$) and defined as
\begin{equation}
    e_u(\m) := \frac{\norm{\bm{u}_{\fom} - \bm{u}_{\rom}}}{\norm{\bm{u}_{\fom}}}\,.
    \label{eq:error_u}
\end{equation}
Apart from the displacement field as the primary unknown, we are interested in the first principal component of the \textsc{Cauchy} stress as this will be used to define a stress constraint for the optimization problem.
The error in the stress is defined as
\begin{equation}
    e_{\sigma}(\m) = \frac{\vert\vb{s}_{\fom} - \vb{s}_{\rom}\vert}{\vert \mathrm{max}(\vb{s}_{\fom})\vert}\,.
    \label{eq:error_sigma}
\end{equation}
Here, $\vb{s}\in\mathbb{R}^{N_g}$ denotes the vector holding the first principal stress values at the $N_g$ integration points of the mesh.
For ease of notation, the parameter-dependence is omitted for $\bm{u}$ and $\vb{s}$.
The minimum, average and maximum of $e_u$ and $e_{\sigma}$ over the validation set are shown in~\cref{fig:relerr}.
With regard to the error in the displacement, the average value is much smaller than the maximum over the validation set.
In both cases, for local basis size ca. $> 75$ the error decreases only very slowly with increasing number of basis functions.
This is due to the rather moderate size of the training set, as \eg{} $N_{\train}=200$ is used for a local parameter space $\mathcal{P}^k=[R_{-}, R_{+}]^4$ for $k=3, \ldots, 9$.
However, the error in the stress is less sensitive to variations in the parameter $\m$ and a pointwise maximum relative error below $1\%$ is acceptable for the current application.
% \comment[id=pd]{Actually, this is probably only because the ROM stress is computed on the full mesh but with reduced $u$ as input. Reduced stress computation?}

\begin{figure}
    \begin{center}
        \includegraphics[width=0.6\textwidth]{relerr.pdf}
    \end{center}
    \caption{Minimum, average (dashed) and maximum relative error over the validation set of size $200$.}\label{fig:relerr}
\end{figure}


% subsection Reduced order model validation (end)

\subsection{Shape optimization} % (fold)
\label{sub:Shape optimization}
The formulation of the shape optimization problem seeks to minimize an objective function, $J(\m, \bm{u}(\m))$, with constraints, $g_q(\m, \bm{u}(\m)) \le 0$, used to limit the first principal stress at each integration point, $q$, with $q=1, \ldots, N_g$.
\begin{align}
    \begin{split}
        \min_{\m\in\mathcal{P}_{\gl}} &J(\m, \bm{u}(\m))\,,\\
        \mathrm{s.t.}\quad & g_q(\m, \bm{u}(\m))\le 0, \quad q=1, \ldots, N_q\,,\\
        \mathrm{with}\quad &\bm{K}(\m)\bm{u}(\m)=\bm{f}\,.
    \end{split}
    \label{eq:shape_opt}
\end{align}
The objective function is defined as a weighted sum of mass $m(\m)$ and compliance $C(\bm{u}(\m))$.
\begin{equation}
    J(\m, \bm{u}(\m))= (1-\omega)\frac{m(\m)}{m(\bar\m)}+\omega \frac{C(\bm{u}(\m))}{C(\bm{u}(\bar\m))}\,,\quad 0\le \omega\le 1\,.
    \label{eq:output}
\end{equation}
The compliance is included, since we do not actively constrain the second principal component and, therefore, designs leading to high compressive stresses would not be detected.
The reference values $m(\bar\m)$ and $C(\bm{u}(\bar\m))$ are thus used to normalize.
The definition of the stress constraint follows a risk factor approach~\cite{Pastore2019Topology} and is written as
\begin{equation}
    g_q(\m, \bm{u}(\m)) = \frac{\vb{s}_q}{\sigma_{+}} - 1\,,\quad q=1,\ldots,N_q\,,
    \label{eq:constraint}
\end{equation}
with the components of the vector of first principal stress $\vb{s}_q$ and an upper bound $\sigma_{+}$ on the admissible tensile stress.
Note that $\vb{s}$ depends on $\bm{u}$ and thus also $\m$ although not explicitly written.

The shape optimization problem~\cref{eq:shape_opt} is then solved using the FOM and the ROM.
Note that the computation of the ROM output $J_n(\m, \bm{u}_n(\m))$, with reduced displacement solution $\bm{u}_n(\m)$, is not dependent on the dimension of the FOM.
The results are obtained using sequential least squares programming~\cite{kraft1988software} (SLSQP) and finite difference approximation of the gradients, and are given in~\cref{tab:opt_result}.
% The relative error in the output $J$ is $\approx\,0.4\%$, while the relative error in the mass $m$ is $\approx\,0.5\%$.
The absolute error in the optimum is $\sqrt{\sum_{i=1}^{10}(\mu_i^{\ast}-\mu_{n,i}^{\ast})^2} \approx 2.44\cdot 10^{-2}$, with the optimum, $\m^{\ast}$, found by the FOM and the optimum, $\m_n^{\ast}$, found by the ROM, respectively.
While the ROM is able to converge to a solution close to the FOM solution, over three times more iterations and function evaluations are necessary.

\begin{table}
    \caption{Result of the optimization. For the ROM a local basis size of $100$ is used. $\m^{\ast}$ is used as a placeholder for the optimum found by the respective model.}\label{tab:opt_result}
    \begin{center}
        \begin{tabularx}{\textwidth}{XXXXX}
            \toprule
            Model & $J(\m^{\ast})$ & $m(\m^{\ast})$ & Iterations & Function calls\\\midrule
            FOM   &  0.941         &  7.855  & 4          & 45\\
            ROM   &  0.946         &  7.897  & 13         & 155\\
            \bottomrule
        \end{tabularx}
    \end{center}
\end{table}

% subsection Shape optimization (end)

\section{CONCLUSIONS} % (fold)
\label{sec:conclusions}
In this contribution a hyper-reduced localized model order reduction framework for the shape optimization of lattice structures is presented.
The data compression strategy, adopted from~\cite{Taddei2018Localization}, is shown to work well with range approximation by random sampling.
Furthermore, the ROM solution of the considered shape optimization problem is in good agreement with the FOM solution and this is regarded as a first proof of concept.
A thorough comparison of the computational efficiency including runtime measurements is planned for future work, as this is out of the scope of the current investigation.
Other directions of future research include the exploration of offline training stategies in which the variation in the parameter value $\m$ and the boundary data $\bm{g}$ are addressed simultaneously, instead of sequentially as this may lead to redundant data in the snapshot set $\bm{S}$.

% section CONCLUSION (end)

% references
\printbibliography[title=REFERENCES]

\end{document}
