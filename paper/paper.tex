\documentclass[a4paper]{eccomas_paper-2024}

\usepackage{graphicx}
\usepackage{subfig}
\usepackage{url}
\usepackage{amsmath}
\usepackage{amsfonts}
\usepackage{amssymb}
\usepackage{bm}
\usepackage{upgreek}
\usepackage{physics}
\usepackage{cleveref}
\usepackage{algorithm, algorithmicx, algpseudocode}

\usepackage{tikz}
\usepackage{standalone}
\usepackage{booktabs}
\usepackage{pgfplotstable}
\pgfplotsset{compat=1.18}
\usetikzlibrary{%
	calc,
	patterns,
	positioning,
	decorations.pathreplacing,%
	decorations.pathmorphing,%
	arrows.meta,%
}
\usepackage{bamcolors}

\usepackage[%
backend=biber,
style=numeric, %alphabetic, numeric
giveninits=true,
natbib=true,
url=false,
doi=true,
eprint=false,
isbn=false,
defernumbers=true,
labelnumber,
hyperref=false,
maxbibnames=3,
sorting=none,%remove this to have things sorted, e.g. use style=alphabetic
]{biblatex}
\addbibresource{main.bib}
\addbibresource{references.bib}

\usepackage[commentmarkup=uwave]{changes}
\usepackage{xspace}

\definechangesauthor[color=blue, name={Philipp Diercks}]{pd}
\definechangesauthor[color=red, name={Joerg F. Unger}]{jfu}
\definechangesauthor[color=orange, name={Annika Robens-Radermacher}]{arr}

% %%% Custom commands
\newcommand{\ie}{i.\,e.\@\xspace}
\newcommand{\eg}{e.\,g.\@\xspace}
% suffixes
\newcommand{\m}{\bm\mu}
\newcommand{\gl}{\mathrm{gl}}
\newcommand{\p}{\mathrm{p}}
\newcommand{\out}{\mathrm{out}}
\newcommand{\inrm}{\mathrm{in}}
% operators
\newcommand{\vecm}{\mathrm{vec}}
\renewcommand{\top}{\mathrm{T}}

\graphicspath{{./img/}}

\title{AN EFFICIENT LOCALIZED MODEL ORDER REDUCTION FRAMEWORK FOR THE SHAPE OPTIMIZATION OF ADDITIVELY MANUFACTURED LATTICE STRUCTURES\break ECCOMAS CONGRESS 2024}

\author{Philipp Diercks$^{1}$, Karen Veroy$^{2}$, Annika Robens-Radermacher$^{1}$ and Jörg F. Unger$^{1}$}

% heading is supposed to contain only the authors (on all pages except the first page)
\heading{Philipp Diercks, Karen Veroy, Annika Robens-Radermacher and Jörg F. Unger}

\address{$^{1}$ Bundesanstalt für Materialforschung und -prüfung, Unter den Eichen 87, 12205 Berlin, \{philipp.diercks, annika.robens-radermacher, joerg.unger\}@bam.de, \url{www.bam.de}
\and
$^{2}$ Centre for Analysis, Scientific Computing and Applications (CASA), Department of Mathematics and Computer Science, TU Eindhoven, P.O. Box 513, 5600 MB Eindhoven, The Netherlands, k.p.veroy@tue.nl}

\keywords{Multiscale methods, Domain decomposition methods, Model order reduction, parameterized PDEs, Shape optimization}

% TODO abstract
\abstract{\comment[id=pd]{TODO: add abstract}.}

\begin{document}
\thispagestyle{empty}

\section{INTRODUCTION}%
\label{sec:introduction}

Additive manufacturing (AM), commonly known as 3D printing, is a manufacturing technique that allows for the production of a wide range of structures and complex geometries.
The objects are build successively by adding material layer by layer from three-dimensional models.
The technology offers numerous advantages over conventional manufacturing, including greater design flexibility, reduced material waste, and the possibility to produce complex structures with tailored material properties.
It has been used in a wide range of applications, including aerospace, biomechanical, automotive, and construction industries~\cite{Plessis2022Properties,Wu2016critical}.

A common engineering practice is to optimize the geometry of a structure by an iterative process, in which an objective function is minimized by systematically choosing parameter values $\bm\mu$ (design variables) and computing the value of the function.
In structural mechanics, a prominent example of an objective function is mass or compliance which is a function of the parameter-dependent displacement field $\bm{u}(\bm\mu)$.
In each iteration of the optimization process, the geometry is manually changed in the CAD model and the high fidelity finite element (FE) model, also called full order model (FOM), is simply re-evaluated.
While this approach is not only an ineffective use of resources, it is also infeasible when solving the FE model is a computationally demanding task, \eg{} in multiscale or large-scale industrial applications.
Due to the prohibitive cost of even a single FOM solution, the iterative design process cannot be performed using direct numerical simulations.
Therefore, we propose a framework based on localized, also called component-based (CB), parametric model order reduction (pMOR).
The main idea is to precompute, in a localized manner, empirical basis functions which approximate the solution for some part of the domain without the need to solve the global FOM even once.
The global approximation is obtained by a suitable coupling of the local reduced spaces spanned by the aforementioned basis functions, in which one naturally relies on domain decomposition (DD) strategies.
A review of concepts in localized model order reduction is presented in~\cite{BuhrReview}.
In particular, regarding lattice structures, this approach allows to take advantage of the repetitiveness of the lattice, such that a computation of the local basis is required only for few components, \ie{} unit cells.

The computation of the local basis is an essential task in localized pMOR and is often done using the concept of oversampling~\cite{Hou1997Multiscale}.
In this approach, the target subdomain $\varOmega_{\mathrm{in}}$, \ie{} that part of the domain for which one would like to construct basis functions, is extended and boundary conditions are prescribed on the boundary of the larger so-called oversampling domain $\varOmega$ to explore possible solutions.
In the literature, this oversampling problem is also expressed in terms of a \textit{transfer operator} $\bm{T}$ that maps the values on the boundary $\partial\varOmega$ to the unknown solution restricted to the target subdomain $\bm{u}(\bm{\mu})\vert_{\varOmega_{\mathrm{in}}}$.
The construction of (optimal) local approximation spaces then comprises the calculation of the left singular vectors of this transfer operator~\cite{Babuska2011Optimal,Smetana2016Optimal}.
The direct calculation via eigenvalue problems is, however, computationally expensive and the range of the transfer operator, and thus the optimal local approximation spaces can be efficiently approximated by random sampling~\cite{Buhr2018Randomized}.
Here, the authors treat non-parametrized partial differential equations (PDEs) and to our knowledge the extension to the parametric setting for linear problems has not been done yet.
In~\cite{Smetana2016Optimal}, the authors propose a spectral greedy algorithm to construct parameter-independent local approximation spaces and Taddei and Patera~\cite{Taddei2018Localization} propose a combination of transfer eigenproblems and proper orthogonal decomposition (POD).
For parameterized nonlinear elliptic PDEs Smetana and Taddei~\cite{Smetana2023Localized} present a randomized local training procedure with global enrichment.

The contributions of the present work are given as follows.
First, as references~\cite{Smetana2016Optimal,Taddei2018Localization} do not make use of range approximation via random sampling, a suitable training strategy to construct local approximation spaces for parameterized linear problems via random sampling is discussed.
Herein, the approach given in~\cite{Taddei2018Localization}, identified as a \textit{distributed approximate POD} (see also~\cite{Himpe2018Hierarchical}), is adopted to range approximation via random sampling.
Second, a framework for the shape optimization of lattice structures is proposed.
It combines the aforementioned algorithm to construct local approximation spaces with an auxiliary problem, as in~\cite{Guo2022Learning}, to facilitate geometrical parametrizations of the unit cell and the matrix version~\cite{Negri2015Efficient} of the empirical interpolation method (EIM)~\cite{Barrault2004‘empirical,Chaturantabut2010Nonlinear} to ensure online efficiency of the final reduced order model (ROM).
Furthermore, the global approximation space is constructed from the local spaces using the partition of unity method or generalized finite element method (GFEM)~\cite{BABUSKA1997,Babuska2004Generalized}.

The rest of the article is organized as follows.
In~\cref{sec:method}, the building blocks of the shape optimization framework are described.
In particular, the range approximation of a parametric transfer operator is discussed.
\Cref{sec:numerical experiments} comprises the numerical experiments.
Based on the example of a graded concrete slab, the quality of the local spaces generated by the proposed method is analyzed, the resulting ROM is validated, and results for the solution of a shape optimization problem are presented.
Finally, conclusions are given in~\cref{sec:conclusions}.

\added[id=pd]{TODO: add note on notation where appropriate.}

\section{METHOD}%
\label{sec:method}
The method proposed in this article is a localized pMOR framework for the shape optimization of lattice structures.
First, the auxiliary problem to model geometrical parameterizations is introduced in~\cref{sub:Auxiliary Problem}.
Second, the construction of local approximation spaces is described in~\cref{sub:Construction of local approximation spaces}.
Herein, the parametric oversampling problem and training strategy to approximate the range of the corresponding parametric transfer operator are discussed.
Third, it is outlined how a global approximation is obtained from local approximation spaces via the GFEM.
Finally, the hyper-reduction (in the form of empirical interpolation) to ensure an online-efficient ROM is detailed in~\cref{sub:Online efficiency}.

\subsection{Auxiliary Problem} % (fold)
\label{sub:Auxiliary Problem}
The approach adopted in this work to facilitate geometrical parameterizations belongs to the class of surface-based deformations~\cite{Botsch2010Polygon} and is based on transformations $\Phi_{\bm\mu}$ that map each material point $\bm{x}_{\mathrm{p}}$ of a parameter-independent reference or parent domain $\varOmega^{\mathrm{p}}$ to a point $\bm{x}_{\bm\mu}$ in the parameter-dependent current or physical domain $\varOmega^{\bm\mu}$.
In the context of shape optimization of lattice structures, our objective is to determine the mapping $\Phi_{\bm\mu}$ for a single unit cell, see~\cref{fig:transformationmap}, and use it to describe the change in geometry of each unit cell throughout the structure.
% The auxiliary problem is formulated here for a single unit cell, and for ease of notation the subscript $i$ as employed in the remainder of the article is dropped.
An auxiliary problem based on the equations of linear elasticity is solved to obtain such domain transformations, following the approach outlined in~\cite{Guo2022Learning}, and briefly repeated here for completeness.

The transformation map $\Phi_{\bm\mu}$ from parent to physical domain $\Phi_{\bm\mu}: \varOmega^{\mathrm{p}}\mapsto\varOmega^{\bm\mu}$ is given by $\bm{x}_{\bm\mu}=\Phi_{\bm\mu}(\bm{x}_{\mathrm{p}}) = \bm{x}_{\mathrm{p}} + \bm{d}(\bm{x}_{\mathrm{p}}; \bm\mu)$, 
with $\bm{d}(\bm{x}_{\mathrm{p}}; \bm{\mu})$ being the transformation displacement field.
The transformation displacement is determined by solving the following linear elastostatic auxiliary problem.
\begin{align}
    \label{eq:aux_1}\div{\left(\hat{\mathbb{C}}\vdot\!\vdot\frac{1}{2}\left(
            \bm{d}\otimes\grad + \grad\otimes\bm{d}
\right)\right)}
            = \bm{0}\,,\quad&\mathrm{in}\;\varOmega^{\mathrm{p}}\,,\\
    \label{eq:aux_2}\bm{d} = \bm{0}\,,\quad&\mathrm{on}\;\partial\varOmega^{\mathrm{p}}\,,\\
    \label{eq:aux_3}\bm{d} = \bm{x}_{\mu} - \bm{x}_{\mathrm{p}}\,,\quad&\mathrm{on}\;\partial\varOmega^{\mathrm{p}}_{\mathrm{int}}\,.
\end{align}
The stiffness tetrad $\hat{\mathbb{C}}$ of the auxiliary problem is defined as
\begin{equation}
    \hat{\mathbb{C}} = \hat{\lambda} \bm{I}\otimes\bm{I} + 2\hat{\mu}\mathbb{I}\,,\quad\mathrm{with}\quad \hat{\lambda}=\frac{\nu}{(1+\nu)(1-2\nu)}\quad\mathrm{and}\quad\hat{\mu}=\frac{1}{2(1+\nu)}\,.
    \label{eq:aux_tetrad}
\end{equation}
With $\bm{x}_{\bm\mu}$ known for all points on the parent interface $\partial\varOmega^{\mathrm{p}}_{\mathrm{int}}$, the desired transformation (\eg{} enlarging/shrinking of the voids radius) is enforced by prescribing~\cref{eq:aux_2,eq:aux_3}.

Given the transformation displacement $\bm{d}(\bm{x}_{\mathrm{p}};\bm\mu)$, the variational formulation is formulated over the parameter-independent parent domain $\varOmega^{\mathrm{p}}$ instead of the parameter-dependent physical domain $\varOmega^{\bm\mu}$.
This introduces the parameter dependence in the variational formulation as shown in the following subsections, but has the advantage that numerical integration can be carried out over the fixed parent domain and thus no re-meshing is required.
However, for each new parameter value $\bm\mu$ for which the model is to be evaluated, we first need to solve the auxiliary problem.
Nevertheless, this does not pose a problem, since the solution of the auxiliary problem is well amenable to acceleration via established MOR techniques and we refer to~\cite{Guo2022Learning} for further details.

\begin{figure}
    \centering
    \include{./img/transformationmap.tex}
    \caption{Transformation map $\Phi_{\bm\mu}$ from parent to physical domain on the example of the unit square domain with a circular void placed in the center. The parameter $\bm\mu$ controls the radius of the void.}\label{fig:transformationmap}
\end{figure}

% subsection Auxiliary Problem (end)

\subsection{Construction of local approximation spaces} % (fold)
\label{sub:Construction of local approximation spaces}
In this paper, local approximation spaces are constructed by solving an oversampling problem many times for different parameter values $\bm\mu$ and different (random) boundary conditions.
It is therefore useful to cast this oversampling problem in the form of a parameter-dependent transfer operator $\bm{T}_{\bm\mu}$ that
maps the boundary function $\bm{g}$ to the solution $\bm{u}(\bm\mu)$ in the target subdomain $\varOmega^{\m}_{\mathrm{in}}$.
The approximation of the range of this transfer operator is then the local approximation space, see~\cite{Buhr2018Randomized}.

First, the global domain $\varOmega_{\mathrm{gl}}^{\bm\mu}$ and a non-overlapping domain decomposition
\begin{equation}
	\varOmega_{\mathrm{gl}}^{\bm\mu}=\cup_{i=1}^{N_{\mathrm{cells}}} \varOmega_i^{\bm\mu}
\end{equation}
is introduced.
In the context of lattice structures, each subdomain $\varOmega_i^{\bm\mu}$ corresponds to a unit cell.
Next, a coarse grid partition of the global domain and a fine grid partition of the unit cell is introduced as shown in~\cref{fig:oversampling_domain}.
\Cref{fig:oversampling_domain} also shows one exemplary oversampling domain $\varOmega^{\bm\mu}$.
The oversampling problem (given for linear elastostatics) then comprises the solution of the following boundary value problem.
\begin{align}
	\begin{split}
	\label{eq:osp_p}
    - \div{\bm{\sigma}} (\bm{u}(\bm\mu)) &= \bm{0} \quad  \mathrm{in}\;{\varOmega^{\bm\mu}}\subset\varOmega^{\bm\mu}_{\mathrm{gl}}\,,\\
    \bm{\sigma}(\bm{u}(\bm\mu)) \vdot \bm{n} &= \bm{0} \quad \mathrm{on}\; \varGamma^{\m}_{\mathrm{N}}:= \partial\varOmega^{\m}\cap\varSigma^{\m}_{\mathrm{N}}\,,\\
    \bm{u}(\bm\mu) &= \bm{0} \quad  \mathrm{on}\;\varGamma^{\m}_{\mathrm{D}}:=\partial\varOmega^{\m}\cap\varSigma^{\m}_{\mathrm{D}}\,,\\
    \bm{u}(\bm\mu) &= \bm{g}\quad\mathrm{on}\;\varGamma^{\m}_{\mathrm{out}}:= \partial\varOmega^{\m} \setminus\partial\varOmega^{\m}_{\mathrm{gl}}\,.
	\end{split}
\end{align}
Here, $\bm\sigma$ is the \textsc{Cauchy} stress, $\bm{n}$ the normal vector and $\bm{g}$ \textsc{Dirichlet} boundary data to be prescribed on the boundary $\varGamma^{\m}_{\out}$.
The boundaries $\varGamma^{\m}_{\mathrm{N}}$ and $\varGamma^{\m}_{\mathrm{D}}$ denote the part of the boundary of the oversampling domain that coincides with the global \textsc{Neumann} boundary $\varSigma^{\m}_{\mathrm{N}}$ or \textsc{Dirichlet} boundary $\varSigma^{\m}_{\mathrm{D}}$, respectively.
Note that the topology is dependent on the target subdomain $\varOmega^{\m}_{\inrm}$ and the size of the oversampled region.
Considering linear elastic isotropic materials
\begin{equation}
    \bm\sigma(\bm{u}(\m)) = \mathbb{C}\vdot\!\vdot\bm\varepsilon(\bm{u}(\m))\,,
    \label{eq:hooke}
\end{equation}
with the linear strain tensor as
\begin{equation}
    \label{eq:eps}
    \bm\varepsilon(\bm{w}):= \frac{1}{2}\left(\bm{w}\otimes\grad + \grad\otimes\bm{w}\right)\,,
\end{equation}
and the stiffness tetrad given in component form as
\begin{equation}
    C_{ijkl} = \lambda \delta_{ij}\delta_{kl} + \mu \left(\delta_{ik}\delta_{jl}+\delta_{il}\delta_{jk}\right)\,,
    \label{eq:stiffness_tetrad}
\end{equation}
the weak form reads
\begin{equation}
    \int_{\varOmega^{\m}} \pdv{\updelta\bm{u}}{\bm{x}^{\m}} \vdot\!\vdot \mathbb{C} \vdot\!\vdot
    \pdv{\bm{u}(\m)}{\bm{x}^{\m}} \dd{\bm{x}^{\m}} = \bm{0}\,.
    % -\int_{\varOmega^{\m}} \pdv{\updelta\bm{u}}{\bm{x}^{\m}} \vdot\!\vdot \mathbb{C} \vdot\!\vdot
    % \pdv{\hat{\bm{g}}}{\bm{x}^{\m}} \dd{\bm{x}^{\m}}\,.
    \label{eq:weak_osp}
\end{equation}
Herein, $\updelta\bm{u}$ denotes the test function.
% Herein, $\updelta\bm{u}$ denotes the test function and $\hat{\bm{g}}$ denotes a suitable lifting function for the inhomogeneous \textsc{Dirichlet} boundary condition and the solution is sought as $\bm{u}(\m)=\bm{u}_0(\m)+\hat{\bm{g}}$.
The weak form is implicitly dependent on the parameter $\m$ due to the integration carried out over the physical domain $\varOmega^{\m}$.
By introducing the deformation gradient of the geometrical transformation\footnote{We note here that the auxiliary problem described in~\cref{sub:Auxiliary Problem} needs to be extended to the oversampling domain, which consists of a union of unit cells. This is straightforward in the current setup, but has the limitation that \cref{eq:aux_2} needs to be satisfied for each unit cell, \ie{} the interfaces between them.} as introduced in~\cref{sub:Auxiliary Problem}
\begin{equation}
    \bm{F}_{\m}:= \dv{\bm{x}^{\m}}{\bm{x}^{\p}}\quad\mathrm{and}\quad
    \dd{\bm{x}^{\m}}=\det(\bm{F}_{\m})\dd{\bm{x}^{\p}}\,,
    \label{eq:F_mu}
\end{equation}
the integration can be carried out over the fixed parent domain
\begin{equation}
    \int_{\varOmega^{\p}} \left(\pdv{\updelta\bm{u}}{\bm{x}^{\p}}\vdot\bm{F}^{-1}_{\m}\right)\vdot\!\vdot \mathbb{C} \vdot\!\vdot
    \left(\pdv{\bm{u}(\m)}{\bm{x}^{\p}}\vdot\bm{F}^{-1}_{\m}\right)\det(\bm{F}_{\m})\dd{\bm{x}^{\p}} = \bm{0}\,.
    \label{eq:weak_osp_parent}
\end{equation}
The solution of the oversampling problem~\cref{eq:osp_p} is then given as the solution of~\cref{eq:weak_osp_parent} and subsequent restriction of the solution to the target subdomain, denoted as $\bm{u}(\m)\big\vert_{\varOmega^{\p}_{\inrm}}$.
The transfer operator $\bm{T}_{\m}: \mathcal{S}\to\mathcal{R}$ maps, for a given parameter value $\m$, the boundary data $\bm{g}$ to the solution on the target subdomain $\bm{u}(\m)\big\vert_{\varOmega^{\p}_{\inrm}} = \bm{T}_{\m}(\bm{g}).$
Here, $\mathcal{S}$ and $\mathcal{R}$ are appropriate source and range spaces, respectively.
Throughout the paper, we assume a suitable discretization and numerical solution of~\cref{eq:weak_osp_parent} using the FE method.
For details concerning the discretization of the transfer operator (for a fixed parameter value), we refer to~\cite{Buhr2018Randomized}.

Finally, we note that the images of $\bm{T}_{\m}$ are computed, such that they do not contain any translations or rotations (rigid body modes are removed via orthogonal projection), \ie{} they comprise purely \textit{deformational modes}.
Moreover, (global) \textsc{Neumann} or \textsc{Dirichlet} boundary conditions prescribed on $\varSigma^{\m}_{\mathrm{N}}$ or $\varSigma^{\m}_{\mathrm{D}}$, respectively, have not been considered yet.
Therefore, an additional \textsc{Neumann} problem\footnote{The case of inhomogeneous \textsc{Dirichlet} boundary conditions can be treated in the same way.} has to be solved to enrich the local spaces.
\begin{align}
	\begin{split}
	\label{eq:neumann_problem}
    - \div{\bm{\sigma}} (\bm{u}(\bm\mu)) &= \bm{0} \quad  \mathrm{in}\;{\varOmega^{\bm\mu}}\subset\varOmega^{\bm\mu}_{\mathrm{gl}}\,,\\
    \bm{\sigma}(\bm{u}(\bm\mu)) \vdot \bm{n} &= \hat{\bm{t}} \quad \mathrm{on}\; \varGamma^{\m}_{\mathrm{N}}:= \partial\varOmega^{\m}\cap\varSigma^{\m}_{\mathrm{N}}\,,\\
    \bm{u}(\bm\mu) &= \bm{0} \quad  \mathrm{on}\;\varGamma^{\m}_{\mathrm{D}}:=\partial\varOmega^{\m}\cap\varSigma^{\m}_{\mathrm{D}}\,,\\
    \bm{u}(\bm\mu) &= \bm{0}\quad\mathrm{on}\;\varGamma^{\m}_{\mathrm{out}}:= \partial\varOmega^{\m} \setminus\partial\varOmega^{\m}_{\mathrm{gl}}\,.
	\end{split}
\end{align}
\Cref{eq:neumann_problem} is solved on the parent domain employing the pull back as above.
Also, for construction of a sufficiently rich local basis it has to be solved for many parameter values $\m$, but a sampling of the boundary values on $\varGamma^{\m}_{\out}$ is not required.
% - setting, global domain = union of non overlapping subdomains = unit cells
% - introduction of coarse grid where each cell corresponds to unit cell subdomain
% - goal of constructing local spaces for only parts of the domain
% - definition of oversampling problem and transfer operator
% these are details of the specific problem we solve later
% - the oversampling problem should be formulated for union of parent unit cells
% - weak formulation is not required here? Should be first introduced in section 2.3?
% - comment on number of archetypes/configurations

\begin{figure}
    \centering
    \include{./img/oversampling_domain.tex}
    \caption{Exemplary coarse grid discretization of the global domain $\varOmega^{\m}_{\gl}$, with target subdomain $\varOmega^{\m}_i$ within oversampling domain $\varOmega^{\m}$ in grey (a) and fine grid discretization of the unit cell (b).}\label{fig:oversampling_domain}
\end{figure}

% TODO adjust abovecaptionskip if necessary
% it seems the default is 6pt (see class file)
% \setlength{\abovecaptionskip}{15pt plus 3pt minus 2pt}

% subsection Construction of local approximation spaces (end)

\subsubsection{Randomized range finder and proper orthogonal decomposition} % (fold)
\label{sec:Randomized range finder and POD}

Assuming a proper FE discretization of $\bm{T}_{\m}$, the algorithm to approximate the range of $\bm{T}_{\m}$ for any $\m$ is discussed next.
Herein, a strategy for the exploration of the parameter space and sampling of the random boundary conditions in the oversampling are the key challenges.
In the present work, the strategy by Taddei \& Patera~\cite{Taddei2018Localization} is adopted in which based on the connection between the POD of images of the transfer operator (for certain boundary conditions) and the singular values of the transfer operator they devise a training strategy which is recognized as a distributed approximate POD (see \cite{Himpe2018Hierarchical}).
For each $\m_j$ in a predefined training set, they compute the singular values of $\bm{T}_{\m_j}$ by solution of an eigenvalue problem and, subsequently, compute the POD over the set of all eigenvectors.
As the authors state, the resolution of the eigenvalue problems may be prohibitive in some cases, and therefore we employ range approximation by random sampling.

The procedure for the computation of parameter-independent deformational modes is summarized in~\cref{algo:rrfpod}.
The target tolerance $\varepsilon^{\ast}$ is used to control the quality of the approximation space (by bounding the mean $\ell^2$-error), and to compute the local tolerances $\varepsilon_{\alpha}$ that steer the range approximation of each transfer operator and the tolerance $\varepsilon_{\rho}$ for the final POD.
First, an empty snapshot set $\bm{S}$ and a training set $\bm{S}_{\mathrm{train}}$ are initialized.
The training set $\bm{S}_{\mathrm{train}}$ has to be sufficiently rich, such that it is a good representation of the parameter space, and the reader is referred to~\cite{Haasdonk2017Chapter}.
Next, for each parameter value $\m_j\in\bm{S}_{\mathrm{train}}$, the range of $\bm{T}_{\m_j}$ which is now fixed with respect to the parameter value is approximated using Algorithm 1 \textsc{AdaptiveRandomizedRangeApproximation} from~\cite{Buhr2018Randomized} and the set of snapshots is extended by Gram Schmidt orthogonalization (line 5 \& 6).
Note that the parameter value $\m$ and boundary conditions $\bm{g}$ are not varied at the same time.
Finally, the POD is computed over the snapshot set $\bm{S}$ which yields the parameter-independent space $X^n$.
The dimension of the local space $X^n$, \ie{} the number of local basis functions is denoted by $n$.

In case of inhomogeneous \textsc{Neumann} boundary conditions, after termination of~\cref{algo:rrfpod}, the \textsc{Neumann} problem~\cref{eq:neumann_problem} is solved for each $\m_j\in\bm{S}_{\mathrm{train}}$ as well.
Following compression via POD the space $X^n$ is enriched by the additional \textsc{Neumann} modes.

\begin{algorithm}
    \caption{Randomized range finder (RRF) combined with POD.}%
    \label{algo:rrfpod}
    \begin{algorithmic}[1]
        \Function{HapodRangeApproximation}{$\bm{T}$, $\varepsilon^{\ast}$, $n_t$, $\varepsilon_{\mathrm{algofail}}$, $N_{\mathrm{train}}$}
        \Statex{\textbf{Input:} Operator $\bm{T}_{\bm\mu}$, target tolerance $\varepsilon^{\ast}$, number of testvectors $n_t$, maximum failure probability $\varepsilon_{\mathrm{algofail}}$, number of parameter samples $N_{\mathrm{train}}$}
    \Statex{\textbf{Output:} space $X^n$}

    \State{Compute $\varepsilon_{\rho}$ and $\varepsilon_{\alpha}$ from $\varepsilon^{\ast}$ according to Theorem 10 of~\cite{Himpe2018Hierarchical}}
    \State{$\bm{S}$ $\gets\;\emptyset$}\Comment{initialize snapshot set}
    \State{$\bm{S}_{\mathrm{train}}\gets\;\{\bm\mu_1,\ldots,\bm\mu_{N_\mathrm{train}}\}$}\Comment{initialize training set}
    \For{$\bm\mu_j$ in $\bm{S}_{\mathrm{train}}$}
    \State{$\bm{R}\gets$ \textsc{AdaptiveRandomizedRangeApproximation}($\bm{T}_{\bm\mu_j}$, $\varepsilon_{\alpha}$, $n_t$, $\varepsilon_{\mathrm{algofail}}$)}
    % \State{$\bm{u}_{\mathrm{Neumann}}(\bm\mu_j)\gets \bm{T}_{\bm\mu_j}(\bm{0})$}\Comment{solve additional Neumann problem if $\varGamma_{\mathrm{N}}\ne\emptyset$}
    % \State{$\bm{R}\gets \bm{R}\cup\left(\bm{u}_{\mathrm{Neumann}}(\bm\mu_j)\right)$}
    \State{$\bm{S}\gets \mathrm{orthonormalize}\left(\bm{S}\cup\bm{R}\right)$}
    \EndFor%
    \State{$\bm{B}\gets\textsc{POD}(\bm{S}, \varepsilon_{\rho})$}
    \State{\textbf{return} {$X^n=\mathrm{span}\left(\bm{B}\right)$}}
    \EndFunction%
    \end{algorithmic} 
\end{algorithm}

% \comment[id=pd]{TODO: explain tolerances to control approximation quality. Refer to HAPOD paper and mention that $\varepsilon^{\ast}$ can be used to compute tolerances at each node of the tree (epsilon star drives the RRF and the final POD. However, this means that we have to use l2-mean error as termination criterion. Too detailed?}
% \comment[id=pd]{TODO: define notation for POD.}

% subsubsection Randomized range finder and POD (end)

\subsection{Construction of a global approximation} % (fold)
\label{sub:Construction of a global approximation}
Given local approximation spaces $X^n_i$ for each target subdomain $\varOmega_i^{\p}$, the construction of a global approximation via the GFEM is discussed.
The difficulty is that the basis functions of the local spaces $X^n_i$ and $X^n_j$ of two neighboring subdomains $\varOmega_i^{\p}$ and $\varOmega_j^{\p}$ are not conforming on the shared interface $\varGamma^{\p}_{ij}=\partial\varOmega_i^{\p}\cap\partial\varOmega_j^{\p}$.
However, given a suitably\footnote{According to Definition 1 of~\cite{BABUSKA1997}.} defined partition of unity $\{{\varphi}_i\}$, the local basis functions can be included in the global FE space by multiplication with the standard FE shape functions ${\varphi}_i$, such that a conforming approximation is obtained.
The global GFEM space is defined as
\begin{equation}
	\label{eq:Xgfem}
    X_{\mathrm{GFEM}}:= \sum_{i} \varphi_iX^n_i = \left\lbrace\sum_i\varphi_i\bm\xi_i \;\big|\; \bm\xi_i\in X^n_i	\right\rbrace\,.
\end{equation}
Furthermore, the GFEM function denoted as $\bm{\psi}(\bm{x}) = \varphi(\bm{x})\bm{\xi}(\bm{x}), \bm{x}\in\omega_{\alpha}$ for a patch $\omega_{\alpha}$ is shown in~\cref{fig:gfem} to illustrate the procedure of constructing the GFEM functions.
\begin{figure}[h]
    \centering
    \subfloat[Linear hat function $\varphi(\bm{x})$]{%
          \includegraphics[height=5cm]{phi.pdf}%
          \label{fig:gfem_left}%
       } 
       \subfloat[Enrichment function $\bm{\xi}(\bm{x})$]{%
          \includegraphics[height=5cm]{enrichment.pdf}%
          \label{fig:gfem_middle}%
       }
       \subfloat[GFEM function $\bm\psi(\bm{x})$]{%
          \includegraphics[height=5cm]{gfem_function.pdf}%
          \label{fig:gfem_right}%
       }
       \caption{Construction of GFEM functions.}
       \label{fig:gfem}
\end{figure} 

% subsection Construction of a global approximation (end)

\subsection{Global solution procedure} % (fold)
\label{sub:Online efficiency}
With the global GFEM space, each coarse grid cell (\ie{} unit cell of the lattice) can be viewed as a high order FE.
For instance, assuming a coarse grid partition as shown in~\cref{fig:oversampling_domain}, the coarse grid cell is a quadrilateral cell with special ansatz functions $\bm{\psi}_i$.
The components of the FE matrix of the $i-$th coarse grid cell are given by
\begin{align}
    \begin{split}
        a^i_{kl} &= \int_{\varOmega^{\p}_i} \left(\pdv{\bm{\psi}_k}{\bm{x}^{\p}}\vdot\bm{F}^{-1}_{\m}\right)\vdot\!\vdot \mathbb{C} \vdot\!\vdot
    \left(\pdv{\bm{\psi}_l}{\bm{x}^{\p}}\vdot\bm{F}^{-1}_{\m}\right)\det(\bm{F}_{\m})\dd{\bm{x}^{\p}}\,,\\
                 &= ({V}^\top)_{km} {K}_{mn}(\mu){V}_{nl}\,.
    \end{split}
    \label{eq:element_matrix}
\end{align}
Here, $\bm{V}$ is the matrix that holds the FE vectors of the GFEM functions $\bm\psi_i$ as column vectors and $\bm{K}(\mu)$ is the stiffness matrix of the subdomain $\varOmega^{\p}_i$ (\ie{} unit cell).
Since $\bm{K}$ is dependent on the parameter $\m$, integration over the full fine scale mesh of the unit cell is required whenever the model is evaluated for a new parameter value which will drastically reduce the computational efficiency of our method.

To overcome this problem, the stiffness matrix $\bm{K}(\m)$ is approximated by Empirical Interpolation~(see \cite{Barrault2004‘empirical,Chaturantabut2010Nonlinear} and in particular \cite{Negri2015Efficient} for the matrix version termed MDEIM employed here), such that
\begin{equation}
    \bm{K}(\m) \approx \bm{K}_Q(\m) =\sum_{q=1}^{Q} \theta_q(\m) \bm{K}_q\,.
    \label{eq:K_ei}
\end{equation}
Herein, $\bm{K}_q$ are parameter-independent matrices that can be precomputed\footnote{Due to the Galerkin projection onto $\bm{V}$ (\cref{eq:element_matrix}) the matrices to be precomputed and stored are also sufficiently small.}.
The $\bm\theta(\m)\in\mathbb{R}^Q$ are called interpolation coefficients and can be determined via the interpolation equation
\begin{equation}
    \bm{\Phi}_{\mathcal{I}}\bm\theta(\m) = \bm{k}_{\mathcal{I}}(\m)\,.
    \label{eq:interp}
\end{equation}
Considering the matrix version of DEIM, the interpolation is constructed for matrices that are vectorized by stacking their columns on top of each other which is denoted by $\bm{k}=\vecm(\bm{K})$.
The suffix $(\cdot)_{\mathcal{I}}$ indicates the restricted evaluation, reduced integration respectively.
The basis $\bm{\Phi}=[\vecm(\bm{K}_1), \ldots, \vecm(\bm{K}_Q)]$ and the interpolation indices $\mathcal{I}$ are determined by applying the DEIM algorithm as proposed in~\cite{Chaturantabut2010Nonlinear} to a set of snapshots $\{\vecm(\bm{K}(\m_1)), \ldots, \vecm(\bm{K}(\m_m))\}$, $m>0$.
By reversing the $\vecm(\cdot)$ operation, the approximation $\bm{K}_Q(\m)$ can be formed using~\cref{eq:K_ei} once the interpolation coefficients are determined by solution of \cref{eq:interp}.
For more details on the overall procedure the reader is referred to~\cite{Negri2015Efficient}.

Finally, with a fast method to compute $\bm{K}_Q(\m)$, the calculation of the FE matrices $a^i_{kl}$ of each coarse grid cell are independent of the underlying fine grid discretization of the unit cell.
The assembly of the global system matrix follows the usual assembly routine for FE methods.

% subsection Online efficiency (end)

\section{NUMERICAL EXPERIMENTS} % (fold)
\label{sec:numerical experiments}

\begin{itemize}
    \item general stuff like FE cell type and degree
    \item software: dolfinx version 0.8.0
    \item PC hardware?
\end{itemize}

% section numerical experiments (end)

\subsection{Graded concrete slab} % (fold)
\label{sub:Graded concrete slab}

\begin{itemize}
    \item introduce graded concrete / problem (gradientenbeton eu); why this is interesting
    \item sketch of the mechanical problem
    \item setup regarding the new method?
\end{itemize}

% \begin{figure}
%     \begin{center}
%         \includegraphics[width=0.95\textwidth]{./figures/beam/beam_sketch.pdf}
%     \end{center}
%     \caption{Schematic representation of the structural problem. A simply supported beam is subjected to a constant load.}\label{fig:beam_sketch}
% \end{figure}
%
% TODO placement
% \begin{figure}
%     \begin{center}
%         \includegraphics[width=0.65\textwidth]{./figures/beam/unit_cell.png}
%     \end{center}
%     \caption{Unit cell domain partition.}\label{fig:unit_cell_domain}
% \end{figure}
%
% \begin{figure}
%     \begin{center}
%         \includegraphics[width=0.95\textwidth]{./figures/beam/global_domain.png}
%     \end{center}
%     \caption{The partition of the global domain. The colors indicate the variation in Young's modulus for each subdomain.}\label{fig:global_domain}
% \end{figure}
%
% subsection Graded concrete slab (end)

\subsection{Projection error study} % (fold)
\label{sub:Projection error study}

% subsection Projection error study (end)

\subsection{Reduced order model validation} % (fold)
\label{sub:Reduced order model validation}

% subsection Reduced order model validation (end)

\subsection{Shape optimization} % (fold)
\label{sub:Shape optimization}

% subsection Shape optimization (end)

\section{CONCLUSIONS} % (fold)
\label{sec:conclusions}

% section CONCLUSION (end)

% \begin{figure}[!htb]
% \minipage{0.49\textwidth}
%   \includegraphics[]{./figures/beam/fig_loc_svals_left.pdf}
%   \caption{Singular valus left}\label{fig:loc_svals_left}
% \endminipage\hfill
% \minipage{0.49\textwidth}
%   \includegraphics[]{./figures/beam/fig_loc_svals_right.pdf}
%   \caption{Singular valus right}\label{fig:loc_svals_right}
% \endminipage\hfill\\%
% \begin{center}
% \minipage{0.49\textwidth}
%   \includegraphics[]{./figures/beam/fig_loc_svals_inner.pdf}
%   \caption{Singular valus inner}\label{fig:loc_svals_inner}
% \endminipage
% \end{center}
% \end{figure}


% \begin{figure}[!htb]
% \minipage{0.49\textwidth}
%   \includegraphics{./figures/beam/fig_proj_error_left_hapod.pdf}
%   \caption{Projection error hapod}\label{fig:proj_error_left_hapod}
% \endminipage\hfill
% \minipage{0.49\textwidth}
%   \includegraphics{./figures/beam/fig_proj_error_right_hapod.pdf}
%   \caption{Projection error hapod}\label{fig:proj_error_right_hapod}
% \endminipage\hfill\\
% \begin{center}
% \minipage{0.49\textwidth}%
%   \includegraphics{./figures/beam/fig_proj_error_inner_hapod.pdf}
%   \caption{Projection error hapod}\label{fig:proj_error_inner_hapod}
% \endminipage
% \end{center}
% \end{figure}

% \begin{table}
%     \centering
%     \caption{HAPOD inner}\label{tab:hapod_inner}
%     \input{./src/beam/tables/hapod_inner.tex}
% \end{table}

% \begin{figure}[!htb]
% \minipage{0.49\textwidth}
%   \includegraphics{./figures/beam/fig_proj_error_left_heuristic.pdf}
%   \caption{Projection error }\label{fig:proj_error_left_heuristic}
% \endminipage\hfill
% \minipage{0.49\textwidth}
%   \includegraphics{./figures/beam/fig_proj_error_right_heuristic.pdf}
%   \caption{Projection error }\label{fig:proj_error_right_heuristic}
% \endminipage\hfill\\
% \begin{center}
% \minipage{0.49\textwidth}%
%   \includegraphics{./figures/beam/fig_proj_error_inner_heuristic.pdf}
%   \caption{Projection error }\label{fig:proj_error_inner_heuristic}
% \endminipage
% \end{center}
% \end{figure}

% \begin{table}
%     \centering
%     \caption{Heuristic rrf inner}\label{tab:heuristic_inner}
%     \input{./src/beam/tables/heuristic_inner.tex}
% \end{table}

% \begin{figure}[!htb]
%     \centering
%     \includegraphics{./figures/beam/fig_loc_rom_error.pdf}
%     \caption{Local ROM error relative to FOM.}\label{fig:loc_rom_error}
% \end{figure}

% \begin{table}
%     \caption{Result of the optimization with FOM and ROM.}\label{tab:minimization_data}
%     \centering
%     \input{./src/beam/tables/minimization_data.tex}
% \end{table}

% \begin{table}
%     \caption{Comparison of reduced optimal solution $\mu_N^{\ast}$ and true optimal solution $\mu^{\ast}$.}\label{tab:minimization_comparison}
%     \centering
%     \input{./src/beam/tables/minimization_comparison.tex}
% \end{table}

% references
\printbibliography[title=REFERENCES]

\end{document}
